{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Copy of Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG-TzddmcuYG"
      },
      "source": [
        "# Training a Convolutional Neural Network for a computer vision binary classification task\n",
        "\n",
        "From https://github.com/dsikar/city-dss-cnn-workshop-1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOVEOBUrW2Jb"
      },
      "source": [
        "# get the data\n",
        "# Install PyDrive\n",
        "!pip install PyDrive\n",
        "\n",
        "#Import modules\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#Get the shareable link e.g. https://drive.google.com/file/d/19sU5tk8RQY605GGjPJMW8mx3S9HrKaFW/view?usp=sharing\n",
        "# Get the id from the link 1JYdxKasFKNfVqx2Iklj7iv_bwPanmi4j\n",
        "downloaded = drive.CreateFile({'id':\"19sU5tk8RQY605GGjPJMW8mx3S9HrKaFW\"})   \n",
        "# Remember at least what was the file extension\n",
        "downloaded.GetContentFile('datasets.tar.gz')       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptqUZ5HFPozd"
      },
      "source": [
        "# list - show manual for ls command: man ls \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLGEP9CUP0RZ"
      },
      "source": [
        "# decompress\n",
        "# man tar - NB exclamation mark is a google colab directive\n",
        "!tar xvf datasets.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2XT37wYcqUY"
      },
      "source": [
        "# list drive contents\n",
        "!ls -lh datasets\n",
        "!ls -l datasets/fire | wc -l\n",
        "!ls -l datasets/nofire | wc -l\n",
        "# note, the dataset is **unbalanced**, more \"fire\" than \"no fire\" examples. Briefly consider self-driving car data\n",
        "# with front camera images mainly taken when driving straight. Fraud detection problem, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B9wUXR7JTIh"
      },
      "source": [
        "# set data location and categories/labels\n",
        "DATADIR = 'datasets/'\n",
        "CATEGORIES = ['nofire', 'fire']\n",
        "print(type(DATADIR))\n",
        "print(type(CATEGORIES))\n",
        "print(CATEGORIES[0])\n",
        "print(CATEGORIES[1])\n",
        "print(type(CATEGORIES[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjzBBu7QJTIk"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "# cv2_imshow - google colab substitute to display images\n",
        "from google.colab.patches import cv2_imshow\n",
        "# plot a couple of images\n",
        "plot_size = 200\n",
        "img_fire = cv2.imread('datasets/fire/20200724_175212_001.jpg')\n",
        "img_fire = cv2.resize(img_fire, (plot_size, plot_size))\n",
        "print(\"FIRE\")\n",
        "cv2_imshow(img_fire)\n",
        "img_no_fire = cv2.imread('datasets/nofire/20200724_175219_001.jpg')\n",
        "print(\"NO FIRE\")\n",
        "img_no_fire = cv2.resize(img_no_fire, (plot_size, plot_size))\n",
        "cv2_imshow(img_no_fire)\n",
        "print(\"\\n\\rimg_no_fire data type:\", type(img_no_fire))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbRgxxmXJTIn"
      },
      "source": [
        "# define function\n",
        "def create_training_data(IMG_SIZE, DATADIR, CATEGORIES):\n",
        "  \"\"\"\n",
        "  Create a training dataset\n",
        "  Arguments:\n",
        "    IMG_SIZE: int, square side size images will be resized to\n",
        "    DATADIR: path to data\n",
        "    CATEGORIES: list, list of classification categories AKA lables\n",
        "  Returns:\n",
        "    training_data: list with training data and categories/labels\n",
        "  \"\"\"\n",
        "  training_data = []\n",
        "  for category in CATEGORIES:  \n",
        "\n",
        "      path = os.path.join(DATADIR,category) # this looks like dataset/fire for index 0\n",
        "      class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=fire, 1=no fire\n",
        "\n",
        "      for img in tqdm(os.listdir(path)):  # iterate over each image\n",
        "          try:\n",
        "              img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
        "              new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
        "              training_data.append([new_array, class_num])  # add array of image array and label to list\n",
        "          except Exception as e:  # todo exception handling\n",
        "              pass\n",
        "            \n",
        "  return training_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I13u9gXEJTIq"
      },
      "source": [
        "# define image size for training data\n",
        "IMG_SIZE = 64 # 64 x 64 pixels\n",
        "training_data = create_training_data(IMG_SIZE, DATADIR, CATEGORIES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dzcLPeIsUhu"
      },
      "source": [
        "# Now we have a list containing image arrays and labels,\n",
        "# let's convince ourselves that the data is in training_data, with the labels\n",
        "# Print first label in training_labels list.\n",
        "print(training_data[0][1]) # the zeroeth label and image\n",
        "cv2_imshow(training_data[0][0])\n",
        "print(training_data[200][1]) # the 200th label and image\n",
        "cv2_imshow(training_data[200][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jHCOODEJTIw"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "# separate elemements of each (image, label) tuple\n",
        "for features,label in training_data: \n",
        "    X.append(features)\n",
        "    Y.append(label)\n",
        "\n",
        "Y = np.asarray(Y)\n",
        "print(Y.shape)\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "X = X/255.0 # normalise pixel values - another big topic we'll not cover for now\n",
        "X.shape[1:] # the input shape of our neural network - VERY IMPORTANT\n",
        "            # all pre-processing must be done to image at \"inference\" time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYOrgGuIJTI3"
      },
      "source": [
        "# Data augmentation - Another important topic we will not cover this time\n",
        "# set up image augmentation\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     horizontal_flip=True,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1\n",
        "#     #zoom_range=0.3\n",
        "#     )\n",
        "#Xaug = datagen.fit(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk3Yk3ZiJTI5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=X.shape[1:]))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=2, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI-InvF_JTI9"
      },
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=100,validation_split=0.3)\n",
        "# model.fit_generator(datagen.flow(X, Y, batch_size=32),\n",
        "#                     epochs=100,\n",
        "#                     verbose=1)\n",
        "\n",
        "#history = model.fit(X, Y, batch_size=27, epochs=10,validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_HTgRTwJTJB"
      },
      "source": [
        "print(type(history))\n",
        "print(history.history.keys())\n",
        "history.history['loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNS9HYtbauXq"
      },
      "source": [
        "# save model\n",
        "model.save('firemodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg7DJagKJTJE"
      },
      "source": [
        "# verify \n",
        "!ls -lh firemodel.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd_tZbhcJTJH"
      },
      "source": [
        "# plot training accuracy\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grxxxEjsJTJK"
      },
      "source": [
        "# plot training loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1NUB5SlJTJQ"
      },
      "source": [
        "# Using the model in practice\n",
        "# load model (for future reference as it is already in memory)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# model = tf.keras.models.load_model('TrainedModels/Fire-64x64-color-v7-soft.h5')\n",
        "model = tf.keras.models.load_model('firemodel.h5')\n",
        "# TODO, download model and run locally"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz2wBaNU27UR"
      },
      "source": [
        "# single prediction fire/no fire\n",
        "plot_size = 64\n",
        "img = cv2.imread('datasets/fire/20200724_175212_001.jpg')\n",
        "# image must go through same transformations\n",
        "img = cv2.resize(img, (plot_size, plot_size))\n",
        "# plot\n",
        "cv2_imshow(img)\n",
        "img = img.astype(\"float32\") / 255.0\n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "print(pred)\n",
        "print(\"Prediction of no fire:\", pred[0])\n",
        "print(\"Prediction of fire:\", pred[1])\n",
        "img = cv2.imread('datasets/nofire/20200724_175219_001.jpg')\n",
        "# image must go through same transformations\n",
        "img = cv2.resize(img, (plot_size, plot_size))\n",
        "cv2_imshow(img)\n",
        "img = img.astype(\"float32\") / 255.0\n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "print(pred)\n",
        "print(\"Prediction of no fire:\", pred[0])\n",
        "print(\"Prediction of fire:\", pred[1])\n",
        "# Takeaways\n",
        "# The training data must be known in order\n",
        "# to interpret results"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}